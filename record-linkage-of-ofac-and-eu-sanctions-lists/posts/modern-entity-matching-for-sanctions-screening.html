<h3>Introduction</h3>

<p>
Sanctions screening is not merely a compliance obligation — it is fundamentally a record linkage problem. Financial institutions must determine whether their customers or transactional counterparties correspond to individuals or entities listed in official sanctions databases.
</p>

<p>
This task is complicated by spelling variations, aliases, transliterations, inconsistent formatting, and multilingual representations. As a result, exact string matching is insufficient. Institutions rely on record linkage techniques to decide whether two records refer to the same real-world entity.
</p>

<p>
In this series, we apply two different matching paradigms to the sanctions screening problem:
</p>

<ul>

<li>A classical approach based on string similarity measures.</li>
<li>A modern approach based on text embeddings and vector similarity.</li>

</ul>

<p>
The objective is to provide an empirical comparison grounded in measurable performance metrics.
</p>

<h3>The experiment</h3>

<p>
Rather than using proprietary customer data, we construct a reproducible experiment using two public sanctions datasets.
</p>

<p>
In operational screening systems, false negatives are inherently difficult to observe: when a sanctioned entity is missed, no alert is generated and the failure may remain unknown. This makes real-world recall measurement highly problematic.
</p>

<p>
To address this limitation, we compare the <a
href="https://sanctionslist.ofac.treas.gov/Home/SdnList" title="OFAC SDN" target="_blank">OFAC SDN List</a> and the <a
href="https://data.europa.eu/data/datasets/consolidated-list-of-persons-groups-and-entities-subject-to-eu-financial-sanctions?locale=en"
title="EU list" target="_blank">EU Consolidated Financial Sanctions List</a> using cross-references provided by <a href="https://www.opensanctions.org/" title="OpenSanctions" target="_blank">OpenSanctions</a>. These established links serve as an externally curated proxy ground truth, enabling controlled evaluation of true positives and false negatives.
</p>

<p>
If you are interested in the raw data acquisition process and structure of these lists, see:
</p>

<ul>
<li><a href="/blog/post/reading-international-sanctions-lists-raw-data/">Reading international sanctions lists from raw data</a></li>
<li><a href="/blog/post/main-international-sanctions-lists-data-sources/">Main international sanctions lists data sources</a></li>
</ul>

<h3>Methodological Framework</h3>

<p>
The experiment follows a structured evaluation framework:
</p>

<ul>
  <li>Extract entity names from both sanctions lists.</li>  
  <li>Apply two matching strategies: classical similarity vs text embeddings.</li>  
  <li>Evaluate performance using a confusion matrix under different thresholds.</li>
</ul>

<p>
Performance evaluation requires a clear definition of what constitutes correct and incorrect matches. The confusion matrix is a standard tool for evaluating binary classification systems. It categorizes predictions into four outcomes based on actual and predicted labels:
</p>

<table>
<tr><th></th><th>Predicted Match</th><th>Predicted Non-Match</th></tr>
<tr><td>Actual Match</td><td>True Positive (TP)</td><td>False Negative (FN)</td></tr>
<tr><td>Actual Non-Match</td><td>False Positive (FP)</td><td>True Negative (TN)</td></tr>
</table>

<p>From the confusion matrix, we compute three primary indicators:</p>

<ul>
<li><strong>Precision</strong> — proportion of predicted matches that are correct</li>
<li><strong>Recall</strong> — proportion of true matches successfully identified</li>
<li><strong>F1 score</strong> — harmonic balance between precision and recall</li>
</ul>

<h3>Scope of the Series</h3>

<p>
This series focuses strictly on entity name matching between sanctions lists. It does not address operational deployment, scalability engineering, or regulatory workflow integration.
</p>

<p>
The goal is to evaluate whether modern embedding-based techniques provide measurable improvements over classical record linkage methods when assessed through a controlled confusion matrix framework.
</p>

<h3>Code and Reproducibility</h3>

<p>
All scripts used in this series are available in this <a href="https://github.com/ejtorre/ejtorreBlog/tree/main/record-linkage-of-ofac-and-eu-sanctions-lists" target="_blank">public repository</a>. The repository includes data preparation, classical matching, embedding pipelines, and shared utilities. All reported results can be reproduced directly.
</p>

<h3>Part of the Series: Modern Entity Matching for Sanctions Screening</h3>

<ul>
  <li><strong>Part 1/4:</strong><a href="/blog/post/modern-entity-matching-for-sanctions-screening"> Modern Entity Matching for Sanctions Screening</a>
  </li>
  <li>Part 2/4: <a href="/blog/post/classical-sanctions-matching-system-implementation-evaluation">Classical Sanctions Matching System — Implementation and Evaluation</a></li>
  <li>Part 3/4: <a href="/blog/post/embedding-based-sanctions-matching-system-implementation-evaluation">Embedding-Based Sanctions Matching System — Implementation and Evaluation</a></li>
  <li>Part 4/4: <a href="/blog/post/operational-considerations-for-sanctions-entity-matching">Operational Considerations for Sanctions Entity Matching</a></li>
</ul>